Content,EventTemplate
Created MRAppMaster for application appattempt_1445144423722_0020_000001,Created MRAppMaster for application appattempt_<*>
Executing with tokens:,Executing with tokens:
"Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 20 cluster_timestamp: 1445144423722 } attemptId: 1 } keyId: -127633188)","Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)"
Using mapred newApiCommitter.,Using mapred newApiCommitter.
OutputCommitter set in config null,OutputCommitter set in config null
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
Default file system [hdfs://msra-sa-41:9000],Default file system [hdfs://<*>:<*>]
Emitting job history data to the timeline server is not enabled,Emitting job history data to the timeline server is not enabled
Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler,Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>
loaded properties from hadoop-metrics2.properties,loaded properties from hadoop-metrics2.properties
Scheduled snapshot period at 10 second(s).,Scheduled snapshot period at <*> second(s).
MRAppMaster metrics system started,MRAppMaster metrics system started
Adding job token for job_1445144423722_0020 to jobTokenSecretManager,Adding job token for job_<*> to jobTokenSecretManager
Not uberizing job_1445144423722_0020 because: not enabled; too many maps; too much input;,Not uberizing job_<*> because: not enabled; too many maps; too much input;
Input size for job job_1445144423722_0020 = 1256521728. Number of splits = 10,Input size for job job_<*> = <*>. Number of splits = <*>
Number of reduces for job job_1445144423722_0020 = 1,Number of reduces for job job_<*> = <*>
job_1445144423722_0020Job Transitioned from NEW to INITED,job_<*>Job Transitioned from NEW to INITED
"MRAppMaster launching normal, non-uberized, multi-container job job_1445144423722_0020.","MRAppMaster launching normal, non-uberized, multi-container job job_<*>."
Using callQueue class java.util.concurrent.LinkedBlockingQueue,Using callQueue class java.util.concurrent.LinkedBlockingQueue
Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
Instantiated MRClientService at MININT-FNANLI5.fareast.corp.microsoft.com/10.86.169.121:62260,Instantiated MRClientService at MININT-<*>/<*>:<*>
IPC Server Responder: starting,IPC Server Responder: starting
IPC Server listener on 62260: starting,IPC Server listener on <*>: starting
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog,Logging to <*>(org.mortbay.log) via <*>
Http request log for http.requests.mapreduce is not defined,Http request log for http.requests.mapreduce is not defined
Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter),Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
adding path spec: /mapreduce/*,adding path spec: /<*>/*
adding path spec: /ws/*,adding path spec: /<*>/*
Jetty bound to port 62267,Jetty bound to port <*>
jetty-6.1.26,jetty-6.1.26
Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\Users\msrabi\AppData\Local\Temp\Jetty_0_0_0_0_62267_mapreduce____.8n7xum\webapp,Extract jar:file:<*> to <*>
Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:62267,Started HttpServer2$SelectChannelConnectorWithSafeStartup@<*>:<*>
Web app /mapreduce started at 62267,Web app /mapreduce started at <*>
Registered webapp guice modules,Registered webapp guice modules
JOB_CREATE job_1445144423722_0020,JOB_CREATE job_<*>
nodeBlacklistingEnabled:true,nodeBlacklistingEnabled:true
maxTaskFailuresPerNode is 3,maxTaskFailuresPerNode is <*>
blacklistDisablePercent is 33,blacklistDisablePercent is <*>
Starting Socket Reader #1 for port 62270,Starting Socket Reader #<*> for port <*>
Connecting to ResourceManager at msra-sa-41/10.190.173.170:8030,Connecting to ResourceManager at <*>/<*>:<*>
"maxContainerCapability: <memory:8192, vCores:32>","maxContainerCapability: <memory:<*>, vCores:<*>>"
queue: default,queue: default
Upper limit on the thread pool size is 500,Upper limit on the thread pool size is <*>
yarn.client.max-cached-nodemanagers-proxies : 0,yarn.client.max-cached-nodemanagers-proxies : <*>
job_1445144423722_0020Job Transitioned from INITED to SETUP,job_<*>Job Transitioned from INITED to SETUP
Processing the event EventType: JOB_SETUP,Processing the event EventType: JOB_SETUP
job_1445144423722_0020Job Transitioned from SETUP to RUNNING,job_<*>Job Transitioned from SETUP to RUNNING
Resolved MSRA-SA-39.fareast.corp.microsoft.com to /default-rack,Resolved <*> to /default-rack
task_1445144423722_0020_m_000001 Task Transitioned from NEW to SCHEDULED,task_<*> Task Transitioned from NEW to SCHEDULED
attempt_1445144423722_0020_r_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED,attempt_<*> TaskAttempt Transitioned from NEW to UNASSIGNED
"mapResourceRequest:<memory:1024, vCores:1>","mapResourceRequest:<memory:<*>, vCores:<*>>"
"Event Writer setup for JobId: job_1445144423722_0020, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job_1445144423722_0020_1.jhist","Event Writer setup for JobId: job_<*>, File: hdfs://<*>"
"reduceResourceRequest:<memory:1024, vCores:1>","reduceResourceRequest:<memory:<*>, vCores:<*>>"
Before Scheduling: PendingReds:1 ScheduledMaps:10 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0,Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
"Recalculating schedule, headroom=<memory:10240, vCores:-17>","Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
Got allocated containers 1,Got allocated containers <*>
Resolved 04DN8IQ.fareast.corp.microsoft.com to /default-rack,Resolved <*> to /default-rack
"Recalculating schedule, headroom=<memory:8192, vCores:-19>","Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.jar,The job-jar file on the remote FS is hdfs://<*>
The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.xml,The job-conf file on the remote FS is <*>
Adding #0 tokens and #1 secret keys for NM use for launching container,Adding #<*> tokens and #<*> secret keys for NM use for launching container
Size of containertokens_dob is 1,Size of containertokens_dob is <*>
Putting shuffle token in serviceData,Putting shuffle token in serviceData
attempt_1445144423722_0020_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED,attempt_<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1445144423722_0020_01_000002 taskAttempt attempt_1445144423722_0020_m_000000_0,Processing the event EventType: CONTAINER_REMOTE_<*> for container container_<*> taskAttempt attempt_<*>
Opening proxy : 04DN8IQ.fareast.corp.microsoft.com:54883,Opening proxy : <*>:<*>
ATTEMPT_START task_1445144423722_0020_m_000000,ATTEMPT_START task_<*>
task_1445144423722_0020_m_000000 Task Transitioned from SCHEDULED to RUNNING,task_<*> Task Transitioned from SCHEDULED to RUNNING
Resolved MININT-FNANLI5.fareast.corp.microsoft.com to /default-rack,Resolved <*> to /default-rack
"Recalculating schedule, headroom=<memory:5120, vCores:-22>","Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
Opening proxy : MININT-FNANLI5.fareast.corp.microsoft.com:52368,Opening proxy : <*>:<*>
TaskAttempt: [attempt_1445144423722_0020_m_000001_0] using containerId: [container_1445144423722_0020_01_000003 on NM: [MININT-FNANLI5.fareast.corp.microsoft.com:52368],TaskAttempt: [attempt_<*>] using containerId: [container_<*>_<*>_<*>_<*> on NM: [<*>:<*>]
"Recalculating schedule, headroom=<memory:4096, vCores:-23>","Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
"Recalculating schedule, headroom=<memory:3072, vCores:-24>","Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
"Recalculating schedule, headroom=<memory:1024, vCores:-26>","Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
Auth successful for job_1445144423722_0020 (auth:SIMPLE),Auth successful for job_<*> (auth:SIMPLE)
"Recalculating schedule, headroom=<memory:0, vCores:-27>","Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
Opening proxy : MSRA-SA-41.fareast.corp.microsoft.com:7109,Opening proxy : <*>:<*>
TaskAttempt: [attempt_1445144423722_0020_m_000003_0] using containerId: [container_1445144423722_0020_01_000005 on NM: [MSRA-SA-41.fareast.corp.microsoft.com:7109],TaskAttempt: [attempt_<*>] using containerId: [container_<*>_<*>_<*>_<*> on NM: [<*>:<*>]
attempt_1445144423722_0020_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING,attempt_<*> TaskAttempt Transitioned from ASSIGNED to RUNNING
Reduce slow start threshold not met. completedMapsForReduceSlowstart 1,Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>
Got allocated containers 2,Got allocated containers <*>
Assigned container container_1445144423722_0020_01_000006 to attempt_1445144423722_0020_m_000004_0,Assigned container container_<*> to attempt_<*>
"getResources() for application_1445144423722_0020: ask=4 release= 0 newContainers=1 finishedContainers=0 resourcelimit=<memory:0, vCores:-27> knownNMs=4","getResources() for application_<*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*>> knownNMs=<*>"
JVM with ID : jvm_1445144423722_0020_m_000009 asked for a task,JVM with ID : jvm_<*> asked for a task
Opening proxy : MSRA-SA-39.fareast.corp.microsoft.com:28345,Opening proxy : <*>:<*>
Launching attempt_1445144423722_0020_m_000009_0,Launching attempt_<*>
Shuffle port returned by ContainerManager for attempt_1445144423722_0020_m_000009_0 : 13562,Shuffle port returned by ContainerManager for attempt_<*> : <*>
"Cannot assign container Container: [ContainerId: container_1445144423722_0020_01_000012, NodeId: MSRA-SA-39.fareast.corp.microsoft.com:28345, NodeHttpAddress: MSRA-SA-39.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 172.22.149.145:28345 }, ] for a map as either  container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true","Cannot assign container Container: [ContainerId: container_<*>, NodeId: <*>:<*>, NodeHttpAddress: <*>:<*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>:<*> }, ] for a map as either  container memory less than required <memory:<*>, vCores:<*>> or no pending map tasks - maps.isEmpty=true"
Container complete event for unknown container id container_1445144423722_0020_01_000012,Container complete event for unknown container id container_<*>
JVM with ID: jvm_1445144423722_0020_m_000010 given task: attempt_1445144423722_0020_m_000008_0,JVM with ID: jvm_<*> given task: <*>_<*>
Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.25258622,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.7607953,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.3624012,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Progress of TaskAttempt attempt_1445144423722_0020_m_000008_0 is : 0.27811313,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Progress of TaskAttempt attempt_1445144423722_0020_m_000009_0 is : 0.667,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.9854844,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 1.0,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Done acknowledgement from attempt_1445144423722_0020_m_000003_0,Done acknowledgement from attempt_<*>
attempt_1445144423722_0020_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED,attempt_<*> TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
Task succeeded with attempt attempt_1445144423722_0020_m_000003_0,Task succeeded with attempt attempt_<*>
task_1445144423722_0020_m_000003 Task Transitioned from RUNNING to SUCCEEDED,task_<*> Task Transitioned from RUNNING to SUCCEEDED
Num completed Tasks: 1,Num completed Tasks: <*>
Reduce slow start threshold reached. Scheduling reduces.,Reduce slow start threshold reached. Scheduling reduces.
All maps assigned. Ramping up all remaining reduces:1,All maps assigned. Ramping up all remaining reduces:<*>
DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445144423722_0020_m_000000,DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_<*>
We launched 1 speculations.  Sleeping 15000 milliseconds.,We launched <*> speculations.  Sleeping <*> milliseconds.
Scheduling a redundant attempt for task task_1445144423722_0020_m_000000,Scheduling a redundant attempt for task task_<*>
Received completed container container_1445144423722_0020_01_000005,Received completed container container_<*>
After Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:1 AssignedMaps:9 AssignedReds:0 CompletedMaps:1 CompletedReds:0 ContAlloc:11 ContRel:1 HostLocal:7 RackLocal:3,After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:0 ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
Diagnostics report from attempt_1445144423722_0020_m_000003_0: Container killed by the ApplicationMaster.,Diagnostics report from attempt_<*>: Container killed by the ApplicationMaster.
Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37551183,Progress of TaskAttempt attempt_<*> is : <*>.<*>
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 32 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 40 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 42 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 47 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 49 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 55 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 59 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
"Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]","Slow ReadProcessor read fields took <*>ms (threshold=<*>ms); ack: seqno: <*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*>, targets: [<*>:<*>, <*>:<*>]"
DFSOutputStream ResponseProcessor exception  for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731,DFSOutputStream ResponseProcessor exception  for block BP-<*>:blk_<*>
"Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731 in pipeline 10.86.169.121:50010, 10.190.173.170:50010: bad datanode 10.190.173.170:50010","Error Recovery for block BP-<*>:blk_<*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>"
DataStreamer Exception,DataStreamer Exception
ERROR IN CONTACTING RM.,ERROR IN CONTACTING RM.
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 65 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030,Address change detected. Old: <*>/<*>:<*> New: <*>:<*>
"Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)","Retrying connect to server: <*>:<*>. Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)"
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 70 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 75 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 84 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost,Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
KILLING attempt_1445144423722_0020_m_000002_0,KILLING attempt_<*>
Processing the event EventType: TASK_ABORT,Processing the event EventType: TASK_ABORT
attempt_1445144423722_0020_m_000002_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED,attempt_<*> TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d,Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@<*>
"Thread Thread[eventHandlingThread,5,main] threw an Exception.","Thread Thread[eventHandlingThread,<*>,main] threw an Exception."
1 failures on node MININT-FNANLI5.fareast.corp.microsoft.com,<*> failures on node MININT-<*>
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 90 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Diagnostics report from attempt_1445144423722_0020_m_000001_0: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost,Diagnostics report from attempt_<*>: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
attempt_1445144423722_0020_m_000001_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP,attempt_<*> TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445144423722_0020_01_000003 taskAttempt attempt_1445144423722_0020_m_000001_0,Processing the event EventType: CONTAINER_REMOTE_<*> for container container_<*> taskAttempt attempt_<*>
Task cleanup failed for attempt attempt_1445144423722_0020_m_000001_0,Task cleanup failed for attempt attempt_<*>
Added attempt_1445144423722_0020_m_000001_1 to list of failed maps,Added attempt_<*> to list of failed maps
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 96 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 100 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 114 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 118 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 121 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 128 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 134 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 144 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 150 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 165 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 172 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 180 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 183 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 187 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 196 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 203 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 208 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 211 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000,Address change detected. Old: <*>/<*>:<*> New: <*>:<*>
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 221 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 225 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 228 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 235 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 240 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 245 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 252 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 255 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 262 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 267 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 270 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 287 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 290 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 295 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 304 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 307 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 312 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 318 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 325 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 329 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 332 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 333 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 336 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 341 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 343 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 346 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 350 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 351 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 354 seconds.  Will retry shortly ...,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...
